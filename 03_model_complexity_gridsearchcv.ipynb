{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.524093\n",
      "n_neighbors: 3, average score: 0.684836\n",
      "n_neighbors: 5, average score: 0.752522\n",
      "n_neighbors: 10, average score: 0.722286\n",
      "n_neighbors: 20, average score: 0.623325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glemaitre/Documents/packages/scikit-learn/sklearn/model_selection/_split.py:419: FutureWarning: You should specify a value for 'n_splits' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4VdW5+PHvmxAIYQhDAIEkJMxDBoaEQURmRFREAQGnq7fKtVbb2qrV1lqK1/uzalu1g73oxQEsCc6oqCiDWouSQJgJ85ABSAIkEMh81u+PdRIOMZAAZ+dkeD/Pkydnn7PPXisbkvestfZ+XzHGoJRSSgH4+boDSiml6g4NCkoppSpoUFBKKVVBg4JSSqkKGhSUUkpV0KCglFKqggYFpZRSFTQoKKWUqqBBQSmlVIUmvu7AxQoJCTERERG+7oZSStUr69evzzHGdKhuv3oXFCIiIkhOTvZ1N5RSql4RkYM12U+nj5RSSlXQoKCUUqqCBgWllFIV6t2aQlVKSkpIT0+nsLDQ111R1QgMDCQ0NJSAgABfd0UpVYUGERTS09Np1aoVERERiIivu6POwxjDsWPHSE9PJzIy0tfdUUpVwbHpIxFZKCJZIrL1PK+LiLwkIntEZLOIDL7UtgoLC2nfvr0GhDpORGjfvr2O6JSqw5xcU3gdmHyB168Ferm/5gIvX05jGhDqB/13UqpucywoGGO+Bo5fYJcbgTeN9R3QRkQ6O9UfpZRqyNbszOKVr/dRXOq6rOP48uqjrkCax3a6+7kfEJG5IpIsIsnZ2dm10rmLkZuby9///vdLeu+UKVPIzc31co+UUo3NknWHeO3b/QT4X95o3JdBoaqem6p2NMYsMMbEGWPiOnSo9i7tWnehoFBWVnbB9y5fvpw2bdo40a3LYozB5bq8TxxKqdpRVFrGN7tzGNu342VP0foyKKQDYR7boUCmj/pyWR577DH27t3LwIEDeeSRR1izZg1jx47l1ltvJTo6GoBp06YxZMgQBgwYwIIFCyreGxERQU5ODgcOHKBfv37ce++9DBgwgEmTJlFQUPCDtj766COGDRvGoEGDmDBhAkePHgUgPz+fu+++m+joaGJiYnj33XcB+Oyzzxg8eDCxsbGMHz8egHnz5vH8889XHDMqKooDBw5U9OH+++9n8ODBpKWl8eMf/5i4uDgGDBjA7373u4r3JCUlceWVVxIbG8vQoUM5deoUo0aNYuPGjRX7jBw5ks2bN3vxTCulqrJu/3HOFJcxvl/Hyz6WLy9JXQY8ICIJwDAgzxhz+HIP+vuPtrE98+Rld85T/y6t+d0NA877+jPPPMPWrVsr/iCuWbOGdevWsXXr1opLLxcuXEi7du0oKCggPj6e6dOn0759+3OOs3v3bpYsWcIrr7zCLbfcwrvvvsvtt99+zj5XXXUV3333HSLCq6++yrPPPssf//hHnnrqKYKDg9myZQsAJ06cIDs7m3vvvZevv/6ayMhIjh+/0BKPtXPnTl577bWKkc/TTz9Nu3btKCsrY/z48WzevJm+ffsya9YsEhMTiY+P5+TJkzRv3px77rmH119/nRdeeIFdu3ZRVFRETExMzU+0UuqSrNyRRbMmfozoHnLZx3IsKIjIEmAMECIi6cDvgAAAY8w/gOXAFGAPcAa426m++MLQoUPPuRb/pZde4v333wcgLS2N3bt3/yAoREZGMnDgQACGDBnCgQMHfnDc9PR0Zs2axeHDhykuLq5o48svvyQhIaFiv7Zt2/LRRx9x9dVXV+zTrl27avvdrVs3hg8fXrG9dOlSFixYQGlpKYcPH2b79u2ICJ07dyY+Ph6A1q1bAzBz5kyeeuopnnvuORYuXMhdd91VbXtKqctjjGFVahYje4bQvKn/ZR/PsaBgjJlTzesG+Im3273QJ/ra1KJFi4rHa9as4csvv2Tt2rUEBQUxZsyYKq/Vb9asWcVjf3//KqePHnzwQX7xi18wdepU1qxZw7x58wD7H6PyXGJVzwE0adLknPUCz7549nv//v08//zzJCUl0bZtW+666y4KCwvPe9ygoCAmTpzIhx9+yNKlSzWbrVK1YG/2aQ4dP8O9V3f3yvE095EXtGrVilOnTp339by8PNq2bUtQUBCpqal89913l9xWXl4eXbvai7TeeOONiucnTZrEX//614rtEydOMGLECL766iv2798PUDF9FBERwYYNGwDYsGFDxeuVnTx5khYtWhAcHMzRo0f59NNPAejbty+ZmZkkJSUBcOrUKUpLSwG45557+OlPf0p8fHyNRiZKqcuzOjULgHF9L389ATQoeEX79u0ZOXIkUVFRPPLIIz94ffLkyZSWlhITE8Nvf/vbc6ZnLta8efOYOXMmo0aNIiTk7PzhE088wYkTJ4iKiiI2NpbVq1fToUMHFixYwM0330xsbCyzZs0CYPr06Rw/fpyBAwfy8ssv07t37yrbio2NZdCgQQwYMID//M//ZOTIkQA0bdqUxMREHnzwQWJjY5k4cWLFaGPIkCG0bt2au+9uULOBStVZK1OP0veKVnRt09wrxxM7i1N/xMXFmcrTEjt27KBfv34+6pHylJmZyZgxY0hNTcXPr+rPHPrvpZR35BWUMOSpL5h7dXcendz3gvuKyHpjTFx1x9SRgvKaN998k2HDhvH000+fNyAopbznm93ZlLqM16aOoIFkSVV1w5133smdd97p624o1WisSs2iTVAAg8Lbeu2Y+nFOKaXqoTKX4aud2Yzp3QF/P+8lmtSgoJRS9dCm9FyOnS5mrBenjkCDglJK1UurU7Pw9xNG9/ZuPjgNCkopVQ+t3JHFkPC2tAlq6tXjalDwgstJnQ3wwgsvcObMGS/2SCnVkB3JK2T74ZOM80ICvMo0KHhBQwgK5XckK6XqvlVevovZkwYFL6icOhvgueeeIz4+npiYmIqU06dPn+a6664jNjaWqKgoEhMTeemll8jMzGTs2LGMHTv2B8eeP38+8fHxREVFMXfuXMpvNtyzZw8TJkwgNjaWwYMHs3fvXgCeffZZoqOjiY2N5bHHHgNgzJgxFXmIcnJyiIiIAOD1119n5syZ3HDDDUyaNIn8/HzGjx/P4MGDiY6O5sMPP6zox5tvvklMTAyxsbHccccdnDp1isjISEpKSgCbEiMiIqJiWynlnFWpWYS2bU6vji29fuyGd5/Cp4/BkS3ePeYV0XDtM+d9uXLq7BUrVrB7927WrVuHMYapU6fy9ddfk52dTZcuXfjkk08Am8coODiYP/3pT6xevfqctBXlHnjgAZ588kkA7rjjDj7++GNuuOEGbrvtNh577DFuuukmCgsLcblcfPrpp3zwwQd8//33BAUF1ShV9tq1a9m8eTPt2rWjtLSU999/n9atW5OTk8Pw4cOZOnUq27dv5+mnn+bbb78lJCSE48eP06pVK8aMGcMnn3zCtGnTSEhIYPr06QQEBFzKGVZK1VBhSRnf7slhZlyoIzXPdaTggBUrVrBixQoGDRrE4MGDSU1NZffu3URHR/Pll1/yq1/9im+++Ybg4OBqj7V69WqGDRtGdHQ0q1atYtu2bZw6dYqMjAxuuukmAAIDAwkKCuLLL7/k7rvvJigoCKhZquyJEydW7GeM4de//jUxMTFMmDCBjIwMjh49yqpVq5gxY0ZF0Crf/5577uG1114D4LXXXtN8R0rVgu/2HaOgpMzrl6KWa3gjhQt8oq8txhgef/xx/uu//usHr61fv57ly5fz+OOPM2nSpIpRQFUKCwu5//77SU5OJiwsjHnz5lWkrj5fu9Wlyq6cstszVfZbb71FdnY269evJyAggIiIiAumyh45ciQHDhzgq6++oqysjKioqPP+LEop71iVmkXzAH9GdG9f/c6XQEcKXlA5dfY111zDwoULyc/PByAjI4OsrCwyMzMJCgri9ttv5+GHH65IX32+1Nvlf8BDQkLIz8/nnXfeAWxRm9DQUD744AMAioqKOHPmDJMmTWLhwoUVi9aeqbLXr18PUHGMquTl5dGxY0cCAgJYvXo1Bw8eBGD8+PEsXbqUY8eOnXNcsKkt5syZo6MEpWrB2YI67QkMuPyCOlXRoOAFlVNnT5o0iVtvvZURI0YQHR3NjBkzOHXqFFu2bGHo0KEMHDiQp59+mieeeAKAuXPncu211/5goblNmzbce++9REdHM23atIpKZwCLFi3ipZdeIiYmhiuvvJIjR44wefJkpk6dSlxcHAMHDqyow/zwww/z8ssvc+WVV5KTk3Pen+O2224jOTmZuLg43nrrLfr2tVkXBwwYwG9+8xtGjx5NbGwsv/jFL855z4kTJ5gz54I1lZRSXrA7K5/0EwWM69vJsTY0dba6LO+88w4ffvghixYtqvF79N9LqUvzj6/28synqax9fBydgy+ufkJNU2c3vDUFVWsefPBBPv30U5YvX+7rrijVKKxKzaJ/59YXHRAuhgYFdcn+8pe/+LoLSjUaeWdKWH/wBD8e3cPRdhrMmkJ9mwZrrPTfSalL89XubMpcxpHUFp4aRFAIDAzk2LFj+genjjPGcOzYMQIDA33dFaXqnVU7jtKuRVNiQ9s42k6DmD4KDQ0lPT2d7OxsX3dFVSMwMJDQ0FBfd0OpeqXMZVizK5txfTp6taBOVRwNCiIyGXgR8AdeNcY8U+n1bsBCoANwHLjdGJN+se0EBAQQGRnphR4rpVTdk3LoBLlnShyfOgIHp49ExB/4G3At0B+YIyL9K+32PPCmMSYGmA/8P6f6o5RS9dUqd0GdUb28W1CnKk6uKQwF9hhj9hljioEE4MZK+/QHVrofr67idaWUavRWpWYRH9GW4ObOJ5x0Mih0BdI8ttPdz3naBEx3P74JaCUiziT0UEqpeigjt4DUI6ccqZ1QFSeDQlWrIZUvD3oYGC0iKcBoIAP4QbUXEZkrIskikqyLyUqpxuRsQR3nUlt4cjIopANhHtuhQKbnDsaYTGPMzcaYQcBv3M/lVT6QMWaBMSbOGBPXoYPzc2pKKVVXrE7NIrxdED06tKh+Zy9wMigkAb1EJFJEmgKzgWWeO4hIiIiU9+Fx7JVISimlgIJiW1BnXN+OjhTUqYpjQcEYUwo8AHwO7ACWGmO2ich8EZnq3m0MsFNEdgGdgKed6o9SStU3a/flUFTqqrX1BHD4PgVjzHJgeaXnnvR4/A5w/gT/SinViK1KzSKoqT/DuldfRdFbGkSaC6WUamiMMazakcVVPUNo1sSZgjpV0aCglFJ10M6jp8jMK6zVqSPQoKCUUnXSyh32UtSxGhSUUkqtTs0iqmtrOrWu3azCGhSUUqqOOXG6mA2HTtTaDWueNCgopVQd89WubFyGWl9PAA0KSilV56xMzSKkZVNiugbXetsaFJRSqg5ZvTOLL7cfZUyfjvg5XFCnKg2i8ppSStV3ZS7Diyt385dVu+l7RWt+MbG3T/qhQUEppXzsxOlifp64ka92ZTN9cChP3xRFYEDt3bDmSYOCUkr50Jb0PO5bvJ7sU0U8fVMUtw4Nr7Xkd1XRoKCUUj6SsO4QTy7bRkiLprx93whiw9r4uksaFJRSqrYVlpTx5IdbWZqczqheIbw4exDtWjT1dbcADQpKKVWr0o6f4b7F69mWeZIHx/Xk5xN64++Dq4zOR4OCUkrVktWpWfw8cSMuY3j1zjgm9K/9O5aro0FBKaUcVvly03/cPphu7WunvObF0qCglFIOqny56X9Pi6J5U99cbloTGhSUUsoBxaUuPt16mGc/21lnLjetCQ0KSinlRYfzCvjn94dYsu4QOfnFdO/QgqX3jWBgHbjctCY0KCil1GUyxrB23zEWrT3Iiu1HcRnD+L4duWNEBKN6hvgkh9Gl0qCglFKXKL+olPc3pPPm2oPszsqnTVAA94yK5PZh3QhrF+Tr7l0SDQpKKXWR9mSdYtHag7y7IYP8olKiuwbz3IwYbojt4rOcRd6iQUEppWqgtMzFlzuyeHPtAf699xhN/f24PqYzd4zoxsCwNnV+AbmmNCgopdQF5OQXkZiUxlvfHSQzr5AuwYE8ck0fZsWHEdKyma+753WOBgURmQy8CPgDrxpjnqn0ejjwBtDGvc9jxpjlTvZJKaWqY4whJS2XN/99gOVbjlBc5uKqniH8buoAxvftSBP/hlufzLGgICL+wN+AiUA6kCQiy4wx2z12ewJYaox5WUT6A8uBCKf6pJRSF1JYUsayTZm8ufYAWzNO0rJZE24dFs7tw7vRs2NLX3evVjg5UhgK7DHG7AMQkQTgRsAzKBigtftxMJDpYH+UUqpKacfPsPi7gyQmp5F7poReHVvy1LQobhrUlZbNGtcsu5M/bVcgzWM7HRhWaZ95wAoReRBoAUxwsD9KKVXB5TJ8vTubN9ceZPXOLPxEuGZAJ+4YHsHw7u0azMLxxXIyKFR1Rk2l7TnA68aYP4rICGCRiEQZY1znHEhkLjAXIDw83JHOKqUah7wzJby9Po3F3x3kwLEzhLRsxoNjezJnWDidg5v7uns+52RQSAfCPLZD+eH00I+AyQDGmLUiEgiEAFmeOxljFgALAOLi4ioHFqWUqta2zDwWrT3IBxszKCxxEdetLQ9N7M21UZ1p2qThLhxfLCeDQhLQS0QigQxgNnBrpX0OAeOB10WkHxAIZDvYJ6VUI1Jc6uKzbUd4898HSD54gsAAP6YN7ModI7oxoEuwr7tXJzkWFIwxpSLyAPA59nLThcaYbSIyH0g2xiwDfgm8IiIPYaeW7jLG6EhAKXVZCorL+L9/7eP1fx8kJ7+Ibu2DeOK6fswcEkZwUICvu1enObqs7r7nYHml5570eLwdGOlkH5RSjYcxhmWbMnnm01QO5xUypk8H/uPKCEb36lCvktL5UuO61kop1WClHDrB/I+3k3IolwFdWvPCrIEM697e192qdzQoKKXqtcN5BTz72U7eT8mgQ6tmPDsjhumDQ/HXkcEl0aCglKqXCorLWPD1Pv7x1V7KjOH+MT24f2zPRnezmbfp2VNK1SuV1w2mRF/B49f2q7f1C+oaDQpKqXpD1w2cp0FBKVXn6bpB7dGgoJSqs3TdoPZVe2bdN6C9ZYw5UQv9UUopXTfwoZqE2yuwtRA2AAuBz/WuY6WUUzam5TL/o21sqO/rBi4XHNsNp45AxFXgVz9qN1cbFIwxT4jIb4FJwN3AX0VkKfB/xpi9TndQKdU4HMkr5NnPUnmvvq4bFOZBejKkJ0HaOshIts8BdB0C1/0Jugz0bR9roEYTc8YYIyJHgCNAKdAWeEdEvjDGPOpkB5VSDVu9XDcoHwWkrYP0dZCWBNmp2BRuAh37w4CbIHQoGBesnA+vjIX4e2HcbyCw7ibjq8mawk+B/wBygFeBR4wxJSLiB+wGNCgopS5a+brBHz5NJbOurxsUnrSf/NOSbBBITzo7CghsA6HxEHWz/d51CAS2Pvf9/W6AVf8N6xbA9g/gmv+BqOlQBwv51CQUhwA3G2MOej5pjHGJyPXOdEsp1ZBVXjf4c11aNygfBZRPA6UnQdYOzo4C+kH/aRA21I4E2vcEv2rqMTRvA9c9DwNvhY8fgnd/BBvehOv+CCG9auOnqjGpbs1YRIYD24wxp9zbrYD+xpjva6F/PxAXF2eSk5N90bRS6jJ5rhuEtGzGo9f0YfoQH68b/GAUkAyFufa1wGD76T90KISVjwIuc+rHVQbJC2HlU1BaACN/BqN+CQHOVn0TkfXGmLhq96tBUEgBBpdfceSeNko2xgz2Sk8vkgYFpeqfc9YNXIYfjYrkJ75YN3C54Nge9zrAeUYBofEXNwq4VKeOwhe/hc2J0DYCpjwPvSY60xY1Dwo1+RcRz0tQ3dNGdXgFSClVV/h83eCcUYD7q/IooP80740CLkarTnDzAhh0O3zyS3hrBvSbCpOfgeCutdePSmryx32fe7H5Zff2/cA+57qklGoIfLZuYAzs+RK++SMc+o6KUUCHvtB/qnsqaCi07+XcKOBiRF4N930L/34Jvn4O9qyEsY/DsPvAv/arxNUkKNwHvAQ8gT27K4G5TnZKKVV/VV43eHZ6TO2sGxgDuz6Dr/4AmSkQHAajf+WeCoqr05eB0qQpXP0wRM+A5Y/Ciieg+AyM+VWtd6XaNYW6RtcUlKqbCorLeOWbfby8ppbXDVwu2LncBoMjm6FNN/sHNma2/WNb3xgDr18PRXlw37+8dlivrSmISCDwI2AAEFj+vDHmPy+rh0qpBsFn6wYuF+xYZqdcjm6Fdt3hxr9DzC0+mXbxGhHoOR5W/t4uRrfqVKvN1ySELwJSgWuA+cBtwA4nO6WUqh98sm7gKrM3gH31HGTvsGsDNy2wN4P5N5BrYMqDwt5VMHBOrTZdkzPY0xgzU0RuNMa8ISL/BD53umNKqbrLJ+sGrjLY+p4dGeTshJA+MP3/bDqJepJsrsY6RUOLDrB3ZZ0MCiXu77kiEoXNfxThWI+UUnVW5XWDH4/p4fy6QVkpbHkbvnne3mPQsT/MfB363Vg3rh5ygp8f9Bhnr6JyuWr156zJv+QCEWmLvfpoGdAS+K2jvVJK1SmV1w2ujbqCX09xeN2grMTe2PX183Biv/30fMsi6Ht9ww0GnnqMtz//kU3QZVCtNXvBoOC+e/mku8DO10D3izm4iEwGXgT8gVeNMc9Uev3PwFj3ZhDQ0RjT5mLaUEo5y3PdoH/n1vxp1kCGO7luUFoMm/5p7zPIPQSdY2H2P6HPlDqZQM4xPcbZ73tW1p2g4L57+QFg6cUeWET8gb8BE4F0bKGeZcaY7R7Hf8hj/weB2vvJlVIXVHnd4A/To5kxJMy5dYPSIkhZDP/6M+SlQZfB7tQPkxpXMCjXsoMNiHtX2Utsa0lNpo++EJGHgUTgdPmTxpjj1bxvKLDHGLMPQEQSgBuB7efZfw7wuxr0RynloMISm6fIc93g/jE9aBXo0GWeJYU2Y+i//gynMm3qietfsFfgNMZg4KnHeHunc+HJH6bjdkhNgkL5/Qg/8XjOUP1UUlcgzWM7HRhW1Y4i0g2IBFbVoD9KKQcYY/ho82GeWb6jYt3g8Wv7Ed7eoXWD4jOw/nX49kXIPwLhI2Da36H7GA0G5XqOh3/9CQ58A32vq5Uma1KOM/ISj13Vv+r5bp+eDbxjjCmr8kAic3Gn1ggPD7/E7iilzmdTWi7zP97O+oMnnF83KD5tU0d/+xKczoKIUTD9Fftdg8G5QodC05b2KqS6EhRE5M6qnjfGvFnNW9OBMI/tUCDzPPvO5tyRSOW2FgALwKa5qKZdpVQNHckr5NnPU3lvQy2sGxTlQ9Ir8O+/wJljEDkaRr8OESO931ZD0aSpTZi3Z6VNf1ELQbMm00fxHo8DgfHABqC6oJAE9BKRSCAD+4f/1so7iUgfbM3ntTXpsFLq8tXqukHhSVuGcu3foOC4nScf/SiED/d+Ww1Rj3E2t9PxfdC+h+PN1WT66EHPbREJxqa+qO59pe4rlz7HXpK60BizTUTmY4v0LHPvOgdIMPUtM59S9VCtrhsU5J4NBoW59iqi0b+yGUtVzfUcb7/vWVk3gkIVzgA1KipqjFkOLK/03JOVtuddQh+UUhep1tYNzhyH7/8B3/3DZvrsMwWufgS6+qRYY/3Xrju0jbQpL4Y5X7WgJmsKH3F2gdgP6M8l3LeglPKNWls3OHPcjgq+/18oPmXvPB79qL3WXl2enuNh4xJ7Y5/D6cBrMlJ43uNxKXDQGJPuUH+UUl5Sa+sGp3Ps4nHSq/bKov432pHBFVHebacx6zHent+07+zCs4NqEhQOAYeNMYUAItJcRCKMMQcc7ZlS6pIYY/h482Ge+TSVjNwC59YN8rPsjVVJ/wclBRB1sw0GHft5tx0FkaPAr4ldV6gDQeFt4EqP7TL3c/FV766U8gVjDMkHT/DMp6kV6wbPz4xlRA8vrxucOmJvOEt+DcqKIHomjHoYOvT2bjvqrGat7M19e1fCxN872lRNgkITY0xx+YYxplhE6mGNO6UaphOni3kvJYPEpEPsOppPSMumzqwb5GXYYLD+dXCVQswsGPVLCOnpvTbU+fUYVyvV2GoSFLJFZGr5JaQiciOQ41iPlFLVcrkMa/cdIyEpjc+3HqG4zMXAsDY8c3M0N8R2oYU36xvkptm8RCmLwLggdg6M+oW9KkbVnlqqxlaT/zn3AW+JyF/d2+lAlXc5K6WcdfRkIe+sTycxKY1Dx88Q3DyAW4eFMys+jH6dvZww7cRBm3cn5S27Peg2uOohaBvh3XZUzdRSNbaa3Ly2FxguIi0BMcaccqw3SqkfKC1zsWZnNglJaazemUWZyzCie3t+Oak31wy4gsAAL5eiPL7P1jLYlADiB4PvtMGgTVj171XOqaVqbDW5T+F/gGeNMbnu7bbAL40xTzjSI6UUAIeOnWFpchpvr0/j6MkiQlo2Y+7V3bklLozIkBbeb/DYXlvlbHOivdIl7kcw8mcQ3NX7balLUwvV2GoyfXStMebX5RvGmBMiMgVbnlMp5UVFpWWs2HaUxKQ0/rUnBz+BMX06Mv/GMMb17UiAvwOfDrN32frHW94G/6Yw7L9sMGh1hffbUpenFqqx1SQo+ItIM2NMEdj7FIBmjvRGqUZq99FTJCSl8d6GdE6cKaFrm+b8YmJvZgwJpUub5s40mrUDvn4Otr4HAc1hxE9gxIOOXtmiLlPLDnBFjKPV2GoSFBYDK0XkNff23cAbjvRGqUbkTHEpH28+TGJSGusPniDAX5jU/wpmxYdxVc8Q/Jwqe3lkqw0G2z+EgCA7KhjxgP2Do+q+nuPtHeQOVWOryULzsyKyGZiALZzzGdDN6z1RqhEwxrAlI4+EpDSWbcwkv6iU7h1a8Jsp/bhpcFdCWjo4CD+8Gb76A6R+DE1b2XsMht8PLRwqpqOc0WO8vUTYoWpsNb2Y+QjgAm4B9gPver0nSjVgeQUlfLgxg4R1aWw/fJLAAD+ui+7C7KFhxHVrizhZPCVjgx0Z7FwOzYJt+uph90FQO+faVM4JG+ZoNbbzBgUR6Y0tjDMHOAYkYi9JHev1XijVABljWLf/OIlJaXyy5TBFpS4GdGnNU9OimBrbheDmDhS08ZSebEcGu1dAYBsY+xsYOhcOoF+9AAAb9ElEQVSat3G2XeUsh6uxXWikkAp8A9xgjNkDICIPebV1pRqgnPwi3nXfYLYv5zStmjVhxpBQ5gwNJ6prsPMdOPS9DQZ7V0LztjDutzYYODD/rHzEwWpsFwoK07EjhdUi8hmQgF1TUEpVUuYyfLM7m8SkNL7YfpRSlyGuW1vuH9uTKdFXENTUi2knqlJ8GrYvgw1vwqF/Q1B7mDAP4u+xydRUw+JgNbbz/k81xrwPvC8iLYBpwENAJxF5GXjfGLPCqz1Rqh7KyC3g7eQ03k5OJyO3gHYtmnL3yAhmxYfRs6PDf4yNgYz1NifRlndtYZu2kTDpvyHuP6GpAze4qbrBwWpsNbn66DTwFjb/UTtgJvAYoEFBNUolZS5W7jhKQlIaX+3KxhgY1SuEX0/px4T+HWnWxMtpJyrLz4bNCZCyGLJToUlzGDANBt0O3UZ6fY5Z1VEOVWO7qDGtMeY48L/uL6Ualf05p0lIOsS769PJyS+mU+tmPDC2J7fEhRHWzoHC957KSu3VJimLYNdnNnV1aDzc8CIMuFnXCxojh6qxOTzRqVT9VlhSxqdbD5OwLo3v9x/H308Y17cjc4aGcXWvDjRxIu2Ep5zddkSwaQnkH7VZMof/GAbeDh37Otu2qtscqsamQUGpKuw4fJKEdYd4PyWDk4WldGsfxKOT+zBjcCgdWwc623hRPmx73waDtO9A/KHXJDs91Psa8Hf4UlZVPzRrBWHDvV6NTYOCUm75RaV8tCmThHWH2JSeR1N/PyZHXcHsoWEMj2zvXNoJsIvGad/b6aGt70PJaWjfEyb8HmJna3I6VbWe42DlfK9WY9OgoBo1YwwpabkkrDvEx5sPc6a4jN6dWvLk9f25aVBX2rZwuPLsqSN2aihlMRzbAwEtIOomGHSHvXNVF43VhfQYb4OCF6uxORoURGQy8CLgD7xqjHmmin1uAeYBBthkjLnVyT4pBT+saxzU1J8bYmzaiYFhbZxNO1FWArs+t4Fg9wowZbYo+1UPQf9p0Kylc22rhuWKGAgK8Wo1NseCgoj4A38DJmJLeCaJyDJjzHaPfXoBjwMj3XUaOjrVH6VcLsN3+46xxKOucWxYG/6fu65xS2/WNa5KVqqdHtqcCKezoWUnuPJBu1YQ0svZtlXD5OdnL031YjU2J38LhgJ7jDH7AEQkAbgR2O6xz73A34wxJwCMMVkO9kc1UlknC3l7fTpLk9M4eOwMrQObOFfXuLLCk7DtPTsqSE+yV4v0nmynh3pOAH+dwVWXycvV2Jz8H9kVSPPYTgeGVdqnN4CIfIudYppnjPnMwT6pRqK0zMVXu7JZsu5sXePh3dvx0ITeTI5yoK6xJ2Pg4Lc2EGz7AEoLoENfe6dxzGytW6C8y8vV2JwMClVNypoq2u8FjAFCgW9EJKq8HnTFgUTmAnMBwsPDvd9T1WCkHT9DYtK5dY3vHdWdWfEO1TX2lJdxdtH4xH5bsyB2lh0VdB2ii8bKGV6uxuZkUEgHwjy2Q4HMKvb5zhhTAuwXkZ3YIJHkuZMxZgGwACAuLq5yYFGNXFFpGV9sP0rCurN1jUf37sDvp4Yzvp9DdY3LlRbBzk9tINi7EowLul0FYx6Dfjdo/iFVO7xYjc3JoJAE9BKRSCADm3G18pVFH2DrNbwuIiHY6aR9DvZJNSC7j54iMSmN91IyOH66mK5tmvPQhN7MjHOwrnG5o9vcdxonQMFxaNUFrvoFDLzV61krlaqWF6uxORYUjDGlIvIA8Dl2vWChMWabiMwHko0xy9yvTRKR7UAZ8Igx5phTfVL135niUj7ZfJgEj7rGE/t3YlZ8OFf1DMHfyRvMCnJh6zs2GGSmgF+A/QUcdAf0GAt+DifCU+p8vFiNTYypX7MxcXFxJjk52dfdULVsS3oeS5IOnVPXeHZ8GDcPDnW2rrHLZT99pSyCHR9BaSF0HACD74DoW7S+sao7/jkbsrbDzzZVuX4lIuuNMXHVHUavh1N1Vl5BCcs2ZpCQlMa2zJM0a+LHdTGdmR0fTnyEw3WNcw/ZtMQbF9vHzYLt/QSDbofOA3XRWNU9A2+Fw5vszZGXkUpbg4KqU4wxJB04QULSIZZvOUxhiYv+nVvz1I0DmDqwq7N1jUsKIfVjOz20bw1gIHI0jHsS+l0PAQ6vUyh1OfpPtV+XSYOCqhNy8ot4b0M6CUlp7Ms+TctmTZg+OJTZ8eFEhzpc1/jwJhsINi+FwlwIDoPRv7KfvNp2c7ZtpeoYDQrKZ8pchn/tySFh3aFz6hr/eEYProvp7Gxd4zPHYcvbdq3gyBbwb2ZHA4Nuh8gxXkkXoFR9pEFB1brM3ALeTrZpJzJyC2gbFMBdV9q6xr06OVjX2FVmp4VSFttporJi6BwLU56HqOkQ1M65tpWqJzQoqFph6xpnkZh0iK92ZeNy1zV+fEpfJvbv5Gxd4+P7YeM/7dfJdAhsA0Pudi8axzjXrlL1kAYF5aj9OadJTErjnfXp5OQX0al1M35SG3WNSwrsJaQpi2D/14DYHDGTnoI+UyDA4eppStVTGhSU1xWWlPHZ1iMkJB3iu31n6xrPjg9jdG8H6xobA5kb7PTQlnehKA/adIOxT9hc88GhzrSrVAOiQUF5zY7DJ0lMSuP9lAzyCkoIbxfEI9f0YcaQUDo5Wdf4dI5NHZyy2N680yQQ+t9op4e6XaWLxkpdBA0K6rJU1DVOSmNTWi5N/f24JuoK5sSHMby7g3WNy0ptVsiURTYhnasEugyG6/9sF40DHb6MVakGSoOCumjldY0T16Xx0ebM2q1rfGyvOxHdEjh1GILaw9C5MOg26DTAuXaVaiQ0KKgayz1TzHsbMkhMSmPn0VMVdY1nDQ1jkJN1jYtPw/YPbTA4+C2IH/ScCNc+a6uYXcYt/Uqpc2lQUBdUXtc4ISmNz7YdobjURWxoMP/v5miuj+lMq0CH0k4YY8tXpiyCre9BcT606w7jn4TYW6F1Z2faVaqR06CgqlRVXeM58WHMig+nfxcH6xrnZ9kaBSmLIWcnBATBgJvsonH4CE1Ep5TDNCioCuV1jROS0liVausaD4ushbrGZSWw+wsbCHZ9BqYMQofC1L/YgNDMwbuclVLn0KCgSDt+hqXJabydnM6Rk4WEtGzKPaMimRUXRvcOLZ1rOHuXnR7alACns6BFRxjxEzsq6NDHuXaVUuelQaGRKq9rnJhk6xqDrWs8b+oAZ+saF52Cbe/bUUHa9yD+0PsaW72s10TwdzA1tlKqWhoUGpk9WadIWHduXeOfje/FzLgwujpV19gYOLTWBoJt70PJGQjpDRPnQ8xsaNXJmXaVUhdNg0IjUF7XODEpjeSDJ2jiZ+sazx7qcF3jk4ft/QQpi+H4XltDNnqGHRWExuuisVJ1kAaFBmxrRh5L1tm6xqeKSuke0oLHr+3L9CEO1jUuLbaLxSmLYc8XYFwQfiWM+iUMmAZNWzjTrlLKKzQoNDAnC0v4MKVSXePozsyKD2NoZDvnbjDL2uG+0zgBzuRAyytg5M9h4G0Q0tOZNpVSXqdBoQEwxpB88ARL1p2ta9yvc2vm3ziAG52sa1yYB1vftcEgYz34NYE+18KgO22aan/976VUfaO/tfXYsfwi3q1U1/jmwaHMjg8jumuwM6MCl8ummkhZBNuXQWkBdOgH1/wPxMyCFiHeb1MpVWs0KNQzrvK6xkm2rnFJmWFIt7Y8O6MH10V3pkUzh/5J89Jh4xLYuBhOHIBmrSF2Ngy+w2Yn1UVjpRoER4OCiEwGXgT8gVeNMc9Uev0u4Dkgw/3UX40xrzrZp/rqcF4BS5POrWt85whb17i3U3WNS4tg53LYsMimqcZAxCgY82vodwM0dbBymlLKJxwLCiLiD/wNmAikA0kisswYs73SronGmAec6kd9VlLmYlVqFgnrztY1vqpnCI9d25dJAxysa3xki10n2JwIBSegdVe4+hEYeCu0i3SmTaVUneDkSGEosMcYsw9ARBKAG4HKQUFVciDnNAmV6hrfP8bWNQ5v79Cn84ITsOUdu1ZweBP4N4W+19mUE93Hgp9DAUgpVac4GRS6Amke2+nAsCr2my4iVwO7gIeMMWlV7NPgFZaU8fm2IyxZd7au8dg+tq7xmD4O1TV2uWD/V3ZUsOMjKCuCTtG2TkH0TAhq5/02lVJ1mpNBoaqVR1Np+yNgiTGmSETuA94Axv3gQCJzgbkA4eHh3u6nT6UeOUnCurN1jcPaNXe+rvGJg7Dxn/Yr75AtXTn4Tjsq6DLQmTaVUvWCk0EhHQjz2A4FMj13MMYc89h8BfhDVQcyxiwAFgDExcVVDiz1Tn5RKR9vymRJpbrGs+PDGOFUXeOSAkj9BDa8aUcHCHQfAxN+B32vhwCHApBSql5xMigkAb1EJBJ7ddFs4FbPHUSkszHmsHtzKrDDwf74lDGGjWm5JHjUNe7VsSW/ddc1budEXWNj4PBGOz205W17s1lwOIx53C4at2lYoy6l1OVzLCgYY0pF5AHgc+wlqQuNMdtEZD6QbIxZBvxURKYCpcBx4C6n+uMruWeKeT8lg4R1tq5x8wB/bojtzKz4cAaHO1TX+Mxx2LzULhof3Qr+zaD/VDs9FHE1+DmUFlspVe+JMfVrNiYuLs4kJyf7uhsX5HIZvtt/jMSkND7dausax4QGMzs+nBtiHapr7CqDvattINi5HMqKocsgGwiipkPztt5vUylVb4jIemNMXHX76R3NXpR1spB3NqSTmHRuXeNb4sMY0CXYmUaP74OUt2yK6pMZ0LwdxP0IBt0GV0Q706ZSqsHSoHCZSstcfL07myXrztY1HhrZjp9P6MW1UZ2dqWtcfAZ2LLNrBQe+AfGDHuNt/qE+10ITh9JiK6UaPA0Klyjt+BneTk5jaW3VNTbGZiJNWQRb34Oik9A2AsY9AbG3QnBX77eplGp0NChchOJSF19sP0pC0qGKusZX9+rAvKn9Gde3E02bOLCAm59t002kLIbsHdCkuS1WM+h2W7xGF42VUl6kQaEG9mSdIjEpjXc32LrGXYIDna1rXFYKe760o4Jdn4GrFLrGwQ0vwoCb7M1mSinlAA0K51FQXMYnWw6TsO5QRV3jCf06MXtoGKN6dXCmrnHOHpuaeuMSyD8CQSEw7D47KujYz/vtKaVUJRoUKtmakUdC0iE+TLF1jSNDWvDYtX2ZPjiUDq0cWMAtyoftH9jpoUNr7aJxr0m2uH2vSdDEgZvalFLqPDQo4K5rvDGTxKRDbM2wdY2nRHdmtlN1jY2BtHWQ8iZsfR9KTkP7njBhHsTMhtadvdueUkrVUKMNCuV1jRPWpfHJlsxz6xrHdiU4yIEbzE4dtfcTpCyGY7shoAVE3WRHBWHDtHqZUsrnGl1QOJZfxHsbMkhIOsTe7NO0aOrPTYNCmTPUobrGZSWwe4WtXrZ7BZgyCBsOI39mryJq5lDVNKWUugSNIiiU1zVOTEpjxfYjlJQZBoe34dnpMVwX41Bd4+yd9uqhTQlwOhtadoIrH7SLxiG9vN+eUkp5QYMOCofzCng72aadyMgtoE1QAHcMj2D2UIfqGheehG3v2emh9CTwawK9J9tA0HMi+Dfo062UagAa3F+p8rrGiUlprNmZhcvAyJ7tnatrbAwc/LcNBNs/gJIzENIHJv03xMyClh29255SSjmowQSFAzmnSUy2dY2zTxXRsVUzfjymB7Piwp2pa3wy01297C2blK5pK1vCctAdEBqni8ZKqXqpXgeF8rrGCevSWLvvGH4C4/p2ZFZ8OGOdqGtcWgy7PrWjgj1fgnFBt6vg6kdtvYKmLbzbnlJK1bJ6GRSqqmv88KTezBgSxhXBDpSVPLrNBoLNiXDmGLTqDFc9BANvg/Y9vN+eUkr5SL0LCnuy8pn8wjc09fdj0oBOzI4P58oeDtQ1LsiFre/aK4gyU8AvAPpOsdNDPcaBnwMpsZVSysfqXVBwGcMT1/Xj5sGh3q9r7HLZ+gQpi229gtJC6DgAJj8D0bdAi/bebU8ppeqYehcUendqxT2junv3oLlpZ+80zj0IzYLt1NCg221JS100Vko1EvUuKHhNSSHs/MQGgr2rAQORo2Hcb6Hf9RDgQEpspZSq4xpfUDi8yb1ovBQKc6F1KIx+FAbeaiuZKaVUI9Y4gsKZ47DlHbtofGQz+DeFfjfY6aHI0bporJRSbg03KLjKYN8aOypI/RjKiuGKGLj2OYieAUHtfN1DpZSqcxpeUDhxwH2n8T8hLw0C28CQu2HQbdA51te9U0qpOs3RoCAik4EXAX/gVWPMM+fZbwbwNhBvjEm+6IZKCmDHR3Z6aP/XgECPsTBxPvSZAgEO3NCmlFINkGNBQUT8gb8BE4F0IElElhljtlfarxXwU+D7i2rAGHtTWcpiu15QlAdtusHY30DsHGgT5qWfRCmlGg8nRwpDgT3GmH0AIpIA3Ahsr7TfU8CzwMM1OqqrFNb+3QaDrG3QJBD6TYXBd9g8RH5ezneklFKNiJNBoSuQ5rGdDgzz3EFEBgFhxpiPReS8QUFE5gJzAYZ09ofPH4cug+G6P0HUdGjexoHuK6VU4+NkUKjqNmBT8aKIH/Bn4K7qDmSMWQAsAIjr3dnw4y+h0wAvdVMppVQ5J+da0gHPif1QINNjuxUQBawRkQPAcGCZiMRd8Kitu2pAUEophzgZFJKAXiISKSJNgdnAsvIXjTF5xpgQY0yEMSYC+A6YeklXHymllPIKx4KCMaYUeAD4HNgBLDXGbBOR+SIy1al2lVJKXTpH71MwxiwHlld67snz7DvGyb4opZSqnl6/qZRSqoIGBaWUUhU0KCillKqgQUEppVQFDQpKKaUqiDGm+r3qEBE5Bez0dT/qiBAgx9edqCP0XJyl5+IsPRdn9THGtKpup/pYT2GnMebCdz03EiKSrOfC0nNxlp6Ls/RcnCUiNboxWKePlFJKVdCgoJRSqkJ9DAoLfN2BOkTPxVl6Ls7Sc3GWnouzanQu6t1Cs1JKKefUx5GCUkoph9T5oCAiB0Rki4hsLF89F5F2IvKFiOx2f2/r637WBhHxF5EUEfnYvR0pIt+7z0OiO0V5gyYigSKyTkQ2icg2Efm9+/nGeC7CRGS1iOxwn4ufuZ9vrL8fC0UkS0S2ejzXKM+FJxGZLCI7RWSPiDxW3f51Pii4jTXGDPS4tOwxYKUxphew0r3dGPwMm4a83B+AP7vPwwngRz7pVe0qAsYZY2KBgcBkERlO4zwXpcAvjTH9sEWqfiIi/Wm8vx+vA5MrPddYzwVgP0gCfwOuBfoDc9z/R86rvgSFym4E3nA/fgOY5sO+1AoRCQWuA151bwswDnjHvUujOA/GyndvBri/DI3zXBw2xmxwPz6F/cDQlUb4+wFgjPkaOF7p6UZ5LjwMBfYYY/YZY4qBBOw5Oa/6EBQMsEJE1ovIXPdznYwxh8H+YgAdfda72vMC8Cjgcm+3B3LdxYzAlj/t6ouO1Tb3NNpGIAv4AthLIz0X5UQkAhgEfE/j/P04n8Z+LroCaR7b1f5u1Ic7mkcaYzJFpCPwhYik+rpDtU1ErgeyjDHrRWRM+dNV7NooLiUzxpQBA0WkDfA+0K+q3Wq3V74jIi2Bd4GfG2NO2kGkUsAl/J2o8yMFY0ym+3sW9g/AUOCoiHQGcH/P8l0Pa8VIYKqIHMAO/8ZhRw5tRKQ8sIcCmb7pnm8YY3KBNdj59EZ5LkQkABsQ3jLGvOd+urH9flxIYz8X6UCYx3a1vxt1OiiISAsRaVX+GJgEbAWWAf/h3u0/gA9908PaYYx53BgTaoyJAGYDq4wxtwGrgRnu3Rr8eQAQkQ7uEQIi0hyYgJ1Lb4znQoD/A3YYY/7k8VKj+v2oRmM/F0lAL/fVeU2xfz+WXegNdfrmNRHpjh0dgJ3q+qcx5mkRaQ8sBcKBQ8BMY0zlBaYGyT199LAx5nr3+UkA2gEpwO3GmCJf9s9pIhKDXTD0x36oWWqMmd9Iz8VVwDfAFs6uNf0au67Q6H4/RGQJMAabGfUo8DvgAxrhufAkIlOwMwv+wEJjzNMX3L8uBwWllFK1q05PHymllKpdGhSUUkpV0KCglFKqggYFpZRSFTQoKKWUqqBBQfmUiBgR+aPH9sMiMs9Lx35dRGZUv+dltzPTnal0tReONV9EJlSzzzwRebiK5yM8M4QqdSk0KChfKwJuFpEQX3fEkzu7ZE39CLjfGDP2cts1xjxpjPnyco9zKS7yZ1YNlAYF5Wul2DKBD1V+ofInfRHJd38fIyJfichSEdklIs+IyG3uOgtbRKSHx2EmiMg37v2ud7/fX0SeE5EkEdksIv/lcdzVIvJP7A1hlfszx338rSLyB/dzTwJXAf8Qkecq7T9GRNaIyDsikioib7nvQkZEhrh/hvUi8rlHKoaKn1lEprjf9y8ReUncdTTc+ruPvU9EfurxfBMRecP9c70jIkHuY40XW4tji9i6A83czx8QkSdF5F/ATBH5qYhsd78/oQb/fqqhMcbol3757AvIB1oDB4Bg4GFgnvu114EZnvu6v48BcoHOQDMgA/i9+7WfAS94vP8z7IefXtg8MIHAXOAJ9z7NgGQg0n3c00BkFf3sgr0jtgP27vpVwDT3a2uAuCreMwbIw+ab8QPWYgNIAPBvoIN7v1nYO00rfmZ3P9PK+wIsAT52P57nfn8z7N27x9zHjMAmOxvp3m+h+3yWH6u3+/k3scnzcJ/3Rz36nAk0cz9u4+v/H/pV+186UlA+Z4w5if1D9dPq9vWQZGw9gSJs6uwV7ue3YP84lltqjHEZY3YD+4C+2Bxad7rTb3+PTUPey73/OmPM/iraiwfWGGOyjU3R/RZwdQ36uc4Yk26McQEb3X3rA0Rhs/5uBJ7ABg5PfYF9Hn1ZUun1T4wxRcaYHGySt07u59OMMd+6Hy/GBqE+wH5jzC73829U6nuix+PNwFsicjt2FKcamfqQOls1Di8AG4DXPJ4rxT3F6Z528Syx6ZnXyOWx7eLc/9eV87gYbDrhB40xn3u+4M4rdfo8/bvUfNSe/Sxz902AbcaYERd4X3XtVXVcOP/PeyGeP/N12IAxFfitiAwwZ+tUqEZARwqqTjA2SdlSzi2jeQAY4n58I3aK5GLNFBE/9zpDd2An8DnwY3faaUSktzsL74V8D4wWkRD3guwc4KtL6A/uPnQQkRHu9gNEZEClfVKB7mKL54CdYqqJ8PLjuvv4L/exIkSkp/v5O6rqu4j4AWHGmNXYgk5tgJY1bFc1EDpSUHXJH4EHPLZfAT4UkXXY+rrn+xR/ITuxfwA7AfcZYwpF5FXsNM4G9wgkm2rKNBpjDovI49gU3QIsN8ZcUhpmY0yxezH5JREJxv4evgBs89inQETuBz4TkRxgXQ0PvwP4DxH5X2A38LL7Z74beFtszYkk4B9VvNcfWOzuk2BrXudeys+o6i/NkqpUHSUiLY0x+e7A9TdgtzHmz77ul2rYdPpIqbrrXvdC9DbslVn/6+P+qEZARwpKKaUq6EhBKaVUBQ0KSimlKmhQUEopVUGDglJKqQoaFJRSSlXQoKCUUqrC/wcSmAd+xDGaSQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.001931\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.035077\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.010721\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.080548\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.023982\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.067599\n",
      "C: 0.010000, gamma: 0.100000, average score: -0.077818\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.058411\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.233360\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.176897\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.504889\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.467730\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.173808\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.571940\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.667942\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.696731\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.535779\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.590511\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.671442\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.741712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested.\n",
    "\n",
    "To inspect training score on the different folds, the parameter ``return_train_score`` is set to ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=(train=-0.000, test=-0.102), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=(train=-0.000, test=-0.010), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=(train=-0.007, test=-0.156), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV]  C=0.001, gamma=0.01, score=(train=0.001, test=-0.100), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV]  C=0.001, gamma=0.01, score=(train=0.002, test=-0.009), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV]  C=0.001, gamma=0.01, score=(train=-0.005, test=-0.154), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV]  C=0.001, gamma=0.1, score=(train=0.009, test=-0.091), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV]  C=0.001, gamma=0.1, score=(train=0.010, test=-0.000), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV]  C=0.001, gamma=0.1, score=(train=0.006, test=-0.142), total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV]  C=0.001, gamma=1, score=(train=0.008, test=-0.092), total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV]  C=0.001, gamma=1, score=(train=0.009, test=-0.001), total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV]  C=0.001, gamma=1, score=(train=0.005, test=-0.145), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=(train=0.001, test=-0.100), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=(train=0.002, test=-0.008), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=(train=-0.005, test=-0.153), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV]  C=0.01, gamma=0.01, score=(train=0.018, test=-0.078), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV]  C=0.01, gamma=0.01, score=(train=0.021, test=0.011), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV]  C=0.01, gamma=0.01, score=(train=0.019, test=-0.128), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV]  C=0.01, gamma=0.1, score=(train=0.086, test=0.023), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV]  C=0.01, gamma=0.1, score=(train=0.098, test=0.092), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV]  C=0.01, gamma=0.1, score=(train=0.122, test=-0.009), total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] . C=0.01, gamma=1, score=(train=0.074, test=0.001), total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] . C=0.01, gamma=1, score=(train=0.088, test=0.080), total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV]  C=0.01, gamma=1, score=(train=0.115, test=-0.041), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV]  C=0.1, gamma=0.001, score=(train=0.020, test=-0.076), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV]  C=0.1, gamma=0.001, score=(train=0.023, test=0.013), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV]  C=0.1, gamma=0.001, score=(train=0.021, test=-0.125), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV]  C=0.1, gamma=0.01, score=(train=0.170, test=0.116), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV]  C=0.1, gamma=0.01, score=(train=0.180, test=0.165), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV]  C=0.1, gamma=0.01, score=(train=0.207, test=0.075), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV]  C=0.1, gamma=0.1, score=(train=0.454, test=0.448), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV]  C=0.1, gamma=0.1, score=(train=0.506, test=0.534), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV]  C=0.1, gamma=0.1, score=(train=0.585, test=0.421), total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .. C=0.1, gamma=1, score=(train=0.447, test=0.403), total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .. C=0.1, gamma=1, score=(train=0.503, test=0.523), total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .. C=0.1, gamma=1, score=(train=0.584, test=0.314), total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV]  C=1, gamma=0.001, score=(train=0.186, test=0.128), total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, gamma=0.001, score=(train=0.194, test=0.180), total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV]  C=1, gamma=0.001, score=(train=0.219, test=0.084), total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] . C=1, gamma=0.01, score=(train=0.553, test=0.580), total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] . C=1, gamma=0.01, score=(train=0.582, test=0.616), total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] . C=1, gamma=0.01, score=(train=0.649, test=0.486), total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .. C=1, gamma=0.1, score=(train=0.641, test=0.717), total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .. C=1, gamma=0.1, score=(train=0.654, test=0.731), total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .. C=1, gamma=0.1, score=(train=0.737, test=0.506), total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] .... C=1, gamma=1, score=(train=0.728, test=0.748), total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] .... C=1, gamma=1, score=(train=0.719, test=0.761), total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] .... C=1, gamma=1, score=(train=0.797, test=0.538), total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV]  C=10, gamma=0.001, score=(train=0.556, test=0.582), total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV]  C=10, gamma=0.001, score=(train=0.583, test=0.619), total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV]  C=10, gamma=0.001, score=(train=0.647, test=0.487), total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV]  C=10, gamma=0.01, score=(train=0.602, test=0.658), total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV]  C=10, gamma=0.01, score=(train=0.620, test=0.686), total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV]  C=10, gamma=0.01, score=(train=0.703, test=0.478), total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] . C=10, gamma=0.1, score=(train=0.648, test=0.722), total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] . C=10, gamma=0.1, score=(train=0.650, test=0.732), total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] . C=10, gamma=0.1, score=(train=0.740, test=0.499), total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ... C=10, gamma=1, score=(train=0.800, test=0.768), total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ... C=10, gamma=1, score=(train=0.794, test=0.803), total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ... C=10, gamma=1, score=(train=0.843, test=0.485), total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.3s finished\n",
      "/home/glemaitre/Documents/packages/scikit-learn/sklearn/model_selection/_search.py:816: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6859234895561204\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>-0.102441</td>\n",
       "      <td>-0.010367</td>\n",
       "      <td>-0.156240</td>\n",
       "      <td>-0.089810</td>\n",
       "      <td>0.059943</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.007087</td>\n",
       "      <td>-0.002532</td>\n",
       "      <td>0.003226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>-0.100450</td>\n",
       "      <td>-0.008522</td>\n",
       "      <td>-0.153649</td>\n",
       "      <td>-0.087669</td>\n",
       "      <td>0.059660</td>\n",
       "      <td>19</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>-0.004749</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>0.002987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>-0.090883</td>\n",
       "      <td>-0.000188</td>\n",
       "      <td>-0.142469</td>\n",
       "      <td>-0.077977</td>\n",
       "      <td>0.058532</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>-0.092246</td>\n",
       "      <td>-0.001084</td>\n",
       "      <td>-0.144674</td>\n",
       "      <td>-0.079464</td>\n",
       "      <td>0.059044</td>\n",
       "      <td>17</td>\n",
       "      <td>0.007544</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.001459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>-0.100247</td>\n",
       "      <td>-0.008341</td>\n",
       "      <td>-0.153377</td>\n",
       "      <td>-0.087451</td>\n",
       "      <td>0.059625</td>\n",
       "      <td>18</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>-0.004532</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>0.002974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.002743      0.000640         0.002580        0.001402   0.001   \n",
       "1       0.002455      0.000303         0.002125        0.000427   0.001   \n",
       "2       0.002057      0.000280         0.001856        0.000360   0.001   \n",
       "3       0.002802      0.000612         0.002121        0.000858   0.001   \n",
       "4       0.001311      0.000337         0.001028        0.000612    0.01   \n",
       "\n",
       "  param_gamma                        params  split0_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}          -0.102441   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}          -0.100450   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}          -0.090883   \n",
       "3           1      {'C': 0.001, 'gamma': 1}          -0.092246   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}          -0.100247   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0          -0.010367          -0.156240        -0.089810        0.059943   \n",
       "1          -0.008522          -0.153649        -0.087669        0.059660   \n",
       "2          -0.000188          -0.142469        -0.077977        0.058532   \n",
       "3          -0.001084          -0.144674        -0.079464        0.059044   \n",
       "4          -0.008341          -0.153377        -0.087451        0.059625   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0               20           -0.000479           -0.000030   \n",
       "1               19            0.001240            0.001885   \n",
       "2               16            0.008541            0.010215   \n",
       "3               17            0.007544            0.009007   \n",
       "4               18            0.001422            0.002082   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0           -0.007087         -0.002532         0.003226  \n",
       "1           -0.004749         -0.000541         0.002987  \n",
       "2            0.006109          0.008288         0.001686  \n",
       "3            0.005453          0.007335         0.001459  \n",
       "4           -0.004532         -0.000342         0.002974  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.685923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.683074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.652406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.651560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.608210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.685923\n",
       "15       1           1         0.683074\n",
       "14       1         0.1         0.652406\n",
       "18      10         0.1         0.651560\n",
       "17      10        0.01         0.608210"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glemaitre/Documents/packages/scikit-learn/sklearn/model_selection/_search.py:816: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............... C=0.001, gamma=0.001, score=-0.457, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ................ C=0.001, gamma=0.01, score=-0.450, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ................. C=0.001, gamma=0.1, score=-0.424, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................... C=0.001, gamma=1, score=-0.429, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ................ C=0.01, gamma=0.001, score=-0.450, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ................. C=0.01, gamma=0.01, score=-0.399, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] .................. C=0.01, gamma=0.1, score=-0.214, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................... C=0.01, gamma=1, score=-0.245, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ................. C=0.1, gamma=0.001, score=-0.395, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................... C=0.1, gamma=0.01, score=0.016, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] .................... C=0.1, gamma=0.1, score=0.558, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ...................... C=0.1, gamma=1, score=0.412, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.054, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.617, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ...................... C=1, gamma=0.1, score=0.514, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................ C=1, gamma=1, score=0.629, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.589, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.508, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ..................... C=10, gamma=0.1, score=0.433, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ....................... C=10, gamma=1, score=0.762, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glemaitre/Documents/packages/scikit-learn/sklearn/model_selection/_split.py:2062: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/14_grid_search.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided hyper-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-optimization of parameters was done up to now by giving some values to be tried. Usually, we could automatically generated those values (randomly or not) by using `RandomSearchCV` or `GridSearchCV`.\n",
    "\n",
    "We could do a little be better by trying some parameters which we could consider more probable to optimize our problem depending on the previous parameters which we used before.\n",
    "\n",
    "We will use `scikit-optimize` to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y\n",
    ")\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# gradient boosted trees tend to do well on problems like this\n",
    "reg = GradientBoostingRegressor(\n",
    "    n_estimators=50, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8849057202369358"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 150],\n",
    "              'max_depth': [3, 5, 8]}\n",
    "grid = GridSearchCV(reg, param_grid=param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glemaitre/Documents/packages/scikit-learn/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=50,\n",
       "                                                 n_iter_no_change=None,\n",
       "                                                 presort='auto', random_state=0,\n",
       "                                                 subsample=1.0, tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [3, 5, 8],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024245</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 50}</td>\n",
       "      <td>0.819007</td>\n",
       "      <td>0.861104</td>\n",
       "      <td>0.814823</td>\n",
       "      <td>0.831611</td>\n",
       "      <td>0.020883</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031056</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.828906</td>\n",
       "      <td>0.875966</td>\n",
       "      <td>0.818028</td>\n",
       "      <td>0.840935</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041141</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 150}</td>\n",
       "      <td>0.829478</td>\n",
       "      <td>0.878341</td>\n",
       "      <td>0.819265</td>\n",
       "      <td>0.842328</td>\n",
       "      <td>0.025755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025966</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.674828</td>\n",
       "      <td>0.809130</td>\n",
       "      <td>0.801843</td>\n",
       "      <td>0.761704</td>\n",
       "      <td>0.061746</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045609</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.677972</td>\n",
       "      <td>0.814940</td>\n",
       "      <td>0.803720</td>\n",
       "      <td>0.765313</td>\n",
       "      <td>0.062173</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.067095</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 150}</td>\n",
       "      <td>0.678523</td>\n",
       "      <td>0.816375</td>\n",
       "      <td>0.803773</td>\n",
       "      <td>0.765992</td>\n",
       "      <td>0.062308</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.046936</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 50}</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.782240</td>\n",
       "      <td>0.763894</td>\n",
       "      <td>0.700643</td>\n",
       "      <td>0.102292</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.089942</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 100}</td>\n",
       "      <td>0.557978</td>\n",
       "      <td>0.783039</td>\n",
       "      <td>0.763166</td>\n",
       "      <td>0.701016</td>\n",
       "      <td>0.101866</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.125472</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 150}</td>\n",
       "      <td>0.557963</td>\n",
       "      <td>0.783046</td>\n",
       "      <td>0.763163</td>\n",
       "      <td>0.701012</td>\n",
       "      <td>0.101875</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.024245      0.002745         0.000730        0.000075   \n",
       "1       0.031056      0.003239         0.000542        0.000043   \n",
       "2       0.041141      0.001800         0.000602        0.000046   \n",
       "3       0.025966      0.001239         0.000558        0.000064   \n",
       "4       0.045609      0.000696         0.000671        0.000009   \n",
       "5       0.067095      0.001412         0.000873        0.000016   \n",
       "6       0.046936      0.001690         0.000704        0.000052   \n",
       "7       0.089942      0.001943         0.001160        0.000113   \n",
       "8       0.125472      0.005778         0.001391        0.000068   \n",
       "\n",
       "  param_max_depth param_n_estimators                                 params  \\\n",
       "0               3                 50   {'max_depth': 3, 'n_estimators': 50}   \n",
       "1               3                100  {'max_depth': 3, 'n_estimators': 100}   \n",
       "2               3                150  {'max_depth': 3, 'n_estimators': 150}   \n",
       "3               5                 50   {'max_depth': 5, 'n_estimators': 50}   \n",
       "4               5                100  {'max_depth': 5, 'n_estimators': 100}   \n",
       "5               5                150  {'max_depth': 5, 'n_estimators': 150}   \n",
       "6               8                 50   {'max_depth': 8, 'n_estimators': 50}   \n",
       "7               8                100  {'max_depth': 8, 'n_estimators': 100}   \n",
       "8               8                150  {'max_depth': 8, 'n_estimators': 150}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.819007           0.861104           0.814823         0.831611   \n",
       "1           0.828906           0.875966           0.818028         0.840935   \n",
       "2           0.829478           0.878341           0.819265         0.842328   \n",
       "3           0.674828           0.809130           0.801843         0.761704   \n",
       "4           0.677972           0.814940           0.803720         0.765313   \n",
       "5           0.678523           0.816375           0.803773         0.765992   \n",
       "6           0.556936           0.782240           0.763894         0.700643   \n",
       "7           0.557978           0.783039           0.763166         0.701016   \n",
       "8           0.557963           0.783046           0.763163         0.701012   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.020883                3  \n",
       "1        0.025118                2  \n",
       "2        0.025755                1  \n",
       "3        0.061746                6  \n",
       "4        0.062173                5  \n",
       "5        0.062308                4  \n",
       "6        0.102292                9  \n",
       "7        0.101866                7  \n",
       "8        0.101875                8  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.887940173555427"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 150}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Gaussian Processes to drive the hyper-parameters optimization. We need to give a range of data to use for each parameter that we want to optimize. In addition, we need to create the objective function which we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "\n",
    "# The list of hyper-parameters we want to optimize. For each one we define the bounds,\n",
    "# the corresponding scikit-learn parameter name, as well as how to sample values\n",
    "# from that dimension (`'log-uniform'` for the learning rate)\n",
    "space  = [Integer(1, 5, name='max_depth'),\n",
    "          Real(10**-5, 10**0, \"log-uniform\", name='learning_rate'),\n",
    "          Integer(1, n_features, name='max_features'),\n",
    "          Integer(2, 100, name='min_samples_split'),\n",
    "          Integer(1, 100, name='min_samples_leaf')]\n",
    "\n",
    "# this decorator allows your objective function to receive a the parameters as\n",
    "# keyword arguments. This is particularly convenient when you want to set scikit-learn\n",
    "# estimator parameters\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_absolute_error\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once those steps performed, we need to call the the optimization loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best score=3.1467'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=50, random_state=0)\n",
    "\n",
    "\"Best score=%.4f\" % res_gp.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the best parameters obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "- max_depth=1\n",
      "- learning_rate=0.194488\n",
      "- max_features=7\n",
      "- min_samples_split=100\n",
      "- min_samples_leaf=13\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Best parameters:\n",
    "- max_depth=%d\n",
    "- learning_rate=%.6f\n",
    "- max_features=%d\n",
    "- min_samples_split=%d\n",
    "- min_samples_leaf=%d\"\"\" % (res_gp.x[0], res_gp.x[1], \n",
    "                            res_gp.x[2], res_gp.x[3], \n",
    "                            res_gp.x[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can check the objective function values depending of the number of time we are calling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEYCAYAAABLOxEiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XuYHFWd//H3Z2aSyf02k4zcQ1ZEAoSwRMWfARKIEbwA6+q6GldUVqKi4qq73vDGymq8764o4XFdcI2wCOJmUTEsMmJUhARzIeEmSiAEcyNhMkmY3L6/P7p60jPpmemaTHdPd39ez9NPqk+dqvqemUl/u+pUnaOIwMzMrFB15Q7AzMwqixOHmZml4sRhZmapOHGYmVkqThxmZpaKE4eZmaXixGFmAEiaLCkkNZQ7FhvcnDisIkh6i6RlktolPSPpZ5JmljuuWiXps5K+X+44rDycOGzQk/Qh4BvAvwAtwLHAt4CLyhlXLn9Lt1rixGGDmqSxwFXA5RHxo4jYGRF7I+J/I+IfkzqNkr4haUPy+oakxmTdLEnrJX1Y0qbkbOUdybozJf1ZUn3O8f5K0qpkuU7SxyQ9LmmrpJslTUjWZS/rXCrpSeAXSfnbJK1L6n9K0hOS5qTY3yWSnpS0RdInc+Kql/SJZNsdkpZLOiZZ92JJd0p6VtIjkv6ml59nq6QvSLpP0nOS/icbQ566R0panOz3D5LelZSfD3wCeFNyBriyX79cq1hOHDbYvRwYBtzWS51PAmcC04HTgJcCV+asfwEwFjgKuBS4RtL4iLgX2Amcm1P3LcAPkuUPABcD5wBHAtuAa7od+xzgJOBVkqaSOROaBxyRc8ysQvY3EzgROA/4tKSTkvIPAW8GXg2MAd4J7JI0ErgziXlSUudbkk7u8acFb0u2PxLYB/xbD/VuBNYn9d4A/Iuk8yLiDjJnf/8dEaMi4rRejmXVKCL88mvQvsh8CP+5jzqPA6/Oef8q4IlkeRawG2jIWb8JODNZ/jzw3WR5NJlEclzy/iHgvJztjgD2Ag3AZCCAKTnrPw3cmPN+BLAHmJNif0fnrL8P+Ntk+RHgojxtfxPwq25lC4HP9PCzagW+mPN+ahJjfU4MDcAxwH5gdE7dLwDXJ8ufBb5f7r8Pv8rz8nVZG+y2As2SGiJiXw91jgTW5bxfl5R17qPbtruAUcnyD4DfSHoP8HrggYjI7us44DZJB3K23U+mnyXrqW5xdL6PiF2StuasL2R/f+4hzmPIJMjujgNeJml7TlkD8F956uaLeR0wBGjuVudI4NmI2NGt7oxe9ms1wpeqbLD7LfA8mUs8PdlA5gM069ikrE8RsZbMB+IFdL1MBZkP2AsiYlzOa1hEPJ27i5zlZ4Cjs28kDQeaUu6vJ08Bf9FD+S+77XNURLynl30dk7N8LJmzni3d6mwAJkga3a1uNlYPq13DnDhsUIuI58hcArpG0sWSRkgaIukCSV9Kqt0IXClpoqTmpH6aW0V/QKb/4Wzghznl1wJXSzoOINl/b3dy3QK8TtL/kzQU+Bygw9hfru8A/yzpBGVMk9QE3A68SNLfJT+XIZJektM3ks9bJU2VNILMjQe3RMT+3AoR8RTwG+ALkoZJmkamf2hRUmUjMFmSP0NqkH/pNuhFxNfIdA5fCWwm8y37fcCPkyqfB5YBq4DVwANJWaFuJNMX8ouIyP3m/a/AYmCJpB3AvcDLeolzDfB+4CYyZx87yPSndPRnf918DbgZWAK0Af8BDE8uJc0F/pbMWcKfgQVAYy/7+i/g+qTuMDJJM583k+n32EDm5oTPRMSdybpsgt0q6YEC22BVQhE+4zQrBkmjgO3ACRHxp3LHA5nbccl0an+n3LFY5fIZh9kAkvS65HLaSOArZM6AnihvVGYDy4nDbGBdRObSzgbgBDK30/q03qqKL1WZmVkqPuMwM7NUqvIBwObm5pg8eXKvdXbu3MnIkSNLE9AgU6ttd7tri9ud3vLly7dExMS+6lVl4pg8eTLLli3rtU5rayuzZs0qTUCDTK223e2uLW53epLW9V3Ll6rMzCwlJw4zM0vFicPMzFJx4jAzs1ScOMzMLJWqvKuqv5bcs5aFi5ayaWsbk5rGMH/eTOaePXXAyktxjEKOvXFLGy03PlrQNmZm3TlxJJbcs5YF1y6hoyMz38/GLW0suHYJqx9+mp+2rjns8qxiHmMgjw04eZhZXlU55MiMGTMi7XMcfz3/OjZuaStaTEMa6gHYu29/HzUHx7Fbmsdw68LLihVSWfi+/tridqcnaXlE9DnLo884Epu2Fi9pQHkSxuEcu9g/DzOrXO4cT0xqGpO3vE4akPLxY0cwfuyIoh5jII/d08/DzMyJIzF/3kwaG7uegDU2NnDR3GkDUv7+t8/i/W+fVdRj9PvYQw8tnz9vJmZm+fhSVSLbEZzv7qJTX3zUgJRnFfMYhRx745Y2Wpq7bvP5f/8ZBw4EzRNG8d6/O9sd42bWs4ioutcZZ5wRfbn77rv7rFOt8rX9XR/9frzi9V+OVQ+tL31AJVKrv3O3u7YcTruBZVHAZ2xJLlVJGibpPkkrJa2R9Lk8dd4tabWkFZKWSpqalE+WtDspXyHp2lLEXGuaJ4wCYPOz7WWOxMwGu1JdquoAzo2IdklDgKWSfhYR9+bU+UFEXAsg6ULga8D5ybrHI2J6iWKtSc3jM+P3b3HiMLM+lCRxJKdA2U+kIckrutXJvf9zZPf1VlwTm0YDThxm1reSPQAoqR5YDrwQuCYiPpqnzuXAh4ChZM5QHpM0GVgDPAq0AVdGxK/ybHsZcBlAS0vLGTfddFOv8bS3tzNq1KjDaVLFytf2Bx7awo/+7wlOO3ECb5w7pUyRFVet/s7d7tpyOO2ePXt2QQ8AlrzjGhgH3A2c0kudtwA3JMuNQFOyfAbwFDCmt2O4c7x3+dp+34on4hWv/3K871M3lT6gEqnV37nbXVuqpnO8W6LaDrRysP8in5uAi5P6HRGxNVleDjwOvKjIYdac5glJH8c2X6oys96V6q6qiZLGJcvDgTnAw93qnJDz9jXAYznb1ifLU4ATgD+WIu5aMnHCwT6OqMLxy8xs4JTqrqojgBuSBFAH3BwRt0u6isyp0WLgfZLmAHuBbcAlybZnA1dJ2gfsB94dEc+WKO6aMXLEUIY1NrD7+b3s2r2HkSMayx2SmQ1SpbqrahVwep7yT+csX9HDtrcCtxYvOgOQRPOE0ax/Zhubn2134jCzHnmsKuvU2c/hW3LNrBdOHNYp28/hp8fNrDdOHNbJT4+bWSGcOKyTnx43s0I4cVinJp9xmFkBnDisU/aMw30cZtYbJw7r1NnH4afHzawXThzWKTsnx9ZtOzlwwE+Pm1l+ThzWaeiQBsaOHs7+/QfY3rar3OGY2SDlxGFdeCZAM+uLE4d14afHzawvThzWRfN4n3GYWe+cOKyLidkOcicOM+uBE4d14T4OM+uLE4d10TzBw46YWe+cOKyLbOe4zzjMrCdOHNZFdmj1rX563Mx64MRhXYwbM5z6OrG9bTd79u4rdzhmNgg5cVgX9fV1NI0/OPSImVl3Thx2iCY/BGhmvXDisEN4Clkz640Thx3CU8iaWW+cOOwQnkLWzHrjxGGH8IROZtYbJw47RPbp8c1bnTjM7FBOHHaIzqHVfcZhZnk4cdghJuaMVxXhKWTNrCsnDjvEyBFDGdbYwO7n97Jr955yh2Nmg4wThx1C0sF+Dt9ZZWbdOHFYXp5C1sx64sRheXkKWTPriROH5ZWdQtZnHGbWnROH5dXsxGFmPXDisLycOMysJ04cllc2cbiPw8y6c+KwvDr7OPz0uJl148RheeXOAnjggJ8eN7ODnDgsr8ahDYwdPZz9+w+wvW1XucMxs0GkJIlD0jBJ90laKWmNpM/lqfNuSaslrZC0VNLUnHUfl/QHSY9IelUpYraDw6u7n8PMchWcOCS9UdLoZPlKST+S9JcFbt4BnBsRpwHTgfMlndmtzg8i4tSImA58CfhacqypwN8CJwPnA9+SVF9o3NZ/zU2+s8rMDpXmjONTEbFD0kzgVcANwLcL2TAysp8+Q5JXdKvTlvN2ZM76i4CbIqIjIv4E/AF4aYq4rZ/89LiZ5dOQou7+5N/XAN+OiP+R9NlCN07OEpYDLwSuiYjf5alzOfAhYChwblJ8FHBvTrX1SVn3bS8DLgNoaWmhtbW113ja29v7rFOtCm37zh1bAVj+wIOMG7qtyFEVX63+zt3u2lKKdqdJHE9Lug6YAyyQ1EiKM5aI2A9MlzQOuE3SKRHxYLc61wDXSHoLcCVwCaB8u8uz/+uA6wBmzJgRs2bN6jWe1tZW+qpTrQpt+/aOFbTe/wwjxzRXxc+qVn/nbndtKUW70ySON5LpY/hSRGyX9ALgI2kPmGzbmuzrwR6q3cTBy2DrgWNy1h0NbEh7XEvvqWe2A3D7Xau5f+U65s+bydyzp7LknrUsXLSUTVvbmNQ0ps9yoNd1ZlZZ+kwcknZw8Bu+gJDUuQyMKWAfE4G9SdIYTnLW0q3OCRHxWPL2NUB2eTHwA0lfA44ETgDu6+uYdniW3LOW2+74fef7jVvaWHDtElY//DQ/bV1DR8e+gsqzFly7JO86Jw+zytNn4oiI0QNwnCOAG5J+jjrg5oi4XdJVwLKIWAy8T9IcYC+wjcxlKiJijaSbgbXAPuDy5LKXFdHCRUvZs7frj7mjYx+3/XzlIXV7K//it34OkHdfCxctdeIwq0BpLlX1W0SsAk7PU/7pnOUretn+auDq4kRn+Wza2tZ3pQJ0TxjFOIaZlVaaS1V5O6kjos9LVVZ5JjWNYeOWQz/YJRFx6BAkPZWPGzMcgO1tu/Mew8wqT593RUXE6IgYk/zb/eX/+VVq/ryZNDZ2/V7R2NjAxXOnpSr/wDtm84F3zKZx6KHr5s+bWZzgzayoUl2qkjSeTOf0sGxZRNwz0EFZ+WX7HvLdCXXqi49KVZ519TfvYP/+AzSNG8nll5zj/g2zClVw4pD098AVZG6HXQGcCfyWgw/qWZWZe/bUvB/uacuz63513x+4+7eP8p6/O9tJw6yCpRly5ArgJcC6iJhNprN7c1Gisqo05dhmAP741JYyR2JmhyNN4ng+Ip4HkNQYEQ8DJxYnLKtG2cTxpyedOMwqWZo+jvXJcCE/Bu6UtA0/wW0pHJ8943DiMKtoBSeOiPirZPGzku4GxgJ3FCUqq0pHtYxj6JB6Nm7Zwc5dHYwc0VjukMysH/o1kVNE/DIiFkfEnoEOyKpXfX0dk49uAnzWYVbJ0kzkdENyqSr7fryk7xYnLKtWvlxlVvnSnHFMi4jt2TcRsY08w4iY9aazg9x3VplVrDSJoy55ABAASRMo0VhXVj2mHOMzDrNKl+aD/6vAbyTdQmbsqr/BAw9aSr5UZVb50txV9T1Jy8g8KS7g9RGxtmiRWVVqaR7NiOFD2d62m23P7WT82JHlDsnMUkp1qSlJFE4W1m+SmHJsMw8+soE/PrmVM0514jCrNP26HdfscBzvfg6ziubEYSU3xf0cZhUtzei45wLzgO3Ag8Aq4MGI6ChSbFalfEuuWWVL08fxfeDyZJtpwMXAycALixCXVbHcM46IQMo3uaSZDVZpEscfIuK2ZPmHxQjGasP4sSMYP3YE257bxcYtO3jBRE8kaVZJ0vRx/FLSP8hfD20AeIh1s8qVJnGcDLwHeEbSTyRdLemNRYrLqlznnVXu5zCrOGkeAHw9gKThZJLIKcDL8GUr6wffWWVWuVKPNRURu4FlycusX3ypyqxy+TkOK4vjj8nMy/HE+q3s33+gzNGYWRpOHFYWI0c00tI8mj179/P0xu19b2Bmg0ZBiUMZxxQ7GKstvlxlVpkKShwREcCPixyL1RgPsW5WmdJcqrpX0kuKFonVnOykTo87cZhVlDR3Vc0G3i3pCWAnmTk5IiKmFSMwq36+VGVWmdIkjguKFoXVpOOOmkBdnVj/zDY69uyjcahnIjarBGkuVT0JnAVcEhHryEwf21KUqKwmNDYO4agXjGP/geDJDc+WOxwzK1Car3jfAg6QmTr2KmAHcCvgfg/rt5HDhwLwjg9/j5bmMcyfN5O5Z09lyT1rWbhoKZu2tjGpqf/lQOe6jVvaaLnx0S7rzCy9NInjZRHxl5J+DxAR2yQNLVJcVgOW3LOWx57Y3Pl+45Y2Fly7hNUPP81PW9fQ0bHvsMqzFly7JO86Jw+z/kmTOPZKqidziQpJE8mcgZj1y8JFSw95aryjYx8//vnKzB/ZYZZ/eeGdncvd1y1ctNSJw6yf0vRx/BtwGzBJ0tXAUuALRYnKasKmrW15y7sngf6W735+L7uf35vq2GbWtzSj4y6StBw4j8ytuBdHxENFi8yq3qSmMWzccugHuASRJxukLR8zahgAbe3P5zn26NTxmllGwWcckhZExMMRcU1EfDMiHpK0oMBth0m6T9JKSWskfS5PnQ9JWitplaS7JB2Xs26/pBXJa3GhMdvgNn/eTBobu353aWxs4OK5pw1I+QcvPZcPXnruIesAhjUOYXvbrgFqiVltSdPH8Urgo93KLshTlk8HcG5EtEsaAiyV9LOIuDenzu+BGRGxS9J7gC8Bb0rW7Y6I6SlitQqQ7WPIdzfUqS8+akDKs7J3VU0YN4KOjn2se/pZ5n3gP2loqOPZ7TsLvkPLzApIHMmH+HuBKZJW5awaDfy6kIMkY121J2+HJK/oVufunLf3Am8tZN9W2eaePTXvh/JAleeua21tZdasWWzeuoP3Xnkjz2w6eJls45Y2rv7mHfz37cv4wxNbOjvtfReW2aEKuVT1auC1QD3wupzXGRFR8Ie7pHpJK4BNwJ0R8bteql8K/Czn/TBJyyTdK+niQo9pls/EptHsP3Bop8j+/Qd45PFNee/0WrhoaanCMxv0FPl6FXMrSGvJXJJaDMwi0zHeKSJSPfIraRyZu7PeHxEP5ln/VuB9wDkR0ZGUHRkRGyRNAX4BnBcRj3fb7jLgMoCWlpYzbrrppl7jaG9vZ9SoUWlCrxq12vbcdl/57+knsPz8+2cMdEgl4d93bTmcds+ePXt5RPT5h15IH8e1wB3A8cByuiaOAKakCSwitktqBc4HuiQOSXOAT5KTNJJtNiT//jHZ9nSgS+KIiOuA6wBmzJgRs2bN6jWO7GWLWlSrbc9td8uNj+a9o6uuThzIczbS0jymYn9m/n3XllK0u89LVRHxbxFxEvCfETElIo7PeRWUNCRNTM40kDQcmAM83K3O6cBC4MKI2JRTPl5SY7LcDLwCWFtg+8zy6umOroteOS1v+fx5M0sZntmgluY5jvdIGg+cAAzLKb+ngM2PAG5InjyvA26OiNslXQUsi4jFwJeBUcAPJQE8GREXAicBCyUdSLb9YkQ4cdhh6euOrq9/5y527OxgxLAhfGT+K90xbpaj4MQh6e+BK4CjgRXAmcBvyQx62KuIWEXm8lL38k/nLM/pYdvfAKcWGqdZoXq7Q2vIkHo+9ZX/5YxpxzlpmHWTZsiRK8iMhLsuImaTSQSbe9/ErDJNahoDwKatO8ocidngkyZxPB8RzwNIaoyIh4ETixOWWXm1NGeGJNm42WNamXWX5snx9UkH94+BOyVtAzYUJyyz8ho/dgT19XVsb9vt2QnNuknTOf5XyeJnJd0NjCVzm65Z1amvr2NS0yie2dTG5q07OPqI8eUOyWzQSHOpqlNE/DIiFkfEnoEOyGyw6Ozn2OJ+DrNc/UocZrVgUrafwx3kZl04cZj1IDtnR74nzM1qWerEIWlk8iCfWVXLnnH4UpVZV30mDkl1kt4i6SeSNpEZKuSZZEKmL0s6ofhhmpVeS7P7OMzyKeSM427gL4CPAy+IiGMiYhJwFpl5M76YjGhrVlWyz3L4IUCzrgq5HXdOROztXpgMp34rcGsyq59ZVfGlKrP8Chkddy+ApG8oGX2wpzpm1WTMqGE0Dm2gfVcHO3d19L2BWY1I0zneDiyWNBJA0lxJBU0da1aJJB28JddnHWadCk4cEXElcCPQKmkp8GHgY8UKzGwwyN6S634Os4PSDKt+HvAuYCeZ+TUujYhHihWY2WDQMtF3Vpl1l+ZS1SeBT0XELOANwH9L6nMuDrNK1uKHAM0OkWaQw3NzlldLuoDMXVX/rxiBmQ0GvrPK7FCFPADY051UzwDn9VbHrNK5j8PsUAU9ACjp/ZKOzS2UNBR4uaQbgEuKEp1ZmfmuKrNDFXKp6nzgncCNko4HtgPDgHpgCfD1iFhRvBDNyqdz2JGtO4gIfHJtVljiWBARV0i6HtgLNAO7I2J7USMzGwRGDB/KqJGNtO/sYHvbbsaPHVHukMzKrpBLVecl//4qIvZGxDNOGlZLWtzPYdZFIYnjDkm/BV4g6Z2SzpA0rNiBmQ0WvrPKrKs+L1VFxEckTQFageOBC4GTJe0BHoyINxU3RLPymtQ5vLqf5TCDAp/jiIg/SpoTEY9myySNAk4pWmRmg0SLp5A166LgBwCBdZLeAkzutt29AxqR2SDTOYXsZicOM0iXOP4HeA5YDniMaasZkzyhk1kXaRLH0RFxftEiMRukWtzHYdZFmkEOfyPp1KJFYjZITWwaBcCWZ9vZv/9AmaMxK780iWMmsFzSI5JWSVotaVWxAjMbLIYOaWD82BHsPxA8u31nucMxK7s0l6ouKFoUZoNcS/Notj23i41bdjAx6Sw3q1VpZgBcl+9VzODMBovssxyel8OssGHVlyb/7pDUlvybffl/kdUED69udlAhT47PTP71+bnVLA87YnZQmjnHZwCfoNsDgBExbeDDMhtcWpw4zDql6RxfBPwjsBrwPYlWU1rcx2HWKU3i2BwRi4sWidkg5qfHzQ5Kkzg+I+k7wF3kDDkSET8a8KjMBpmmcSOprxPPbt/Fnr37GDokzX8ds+qS5gHAdwDTyUwl+7rk9dpCNpQ0TNJ9klZKWiPpc3nqfEjS2uThwrskHZez7hJJjyUvz29uJVdfX0fThMwT5Ju3tpc5GrPySvO16bSI6O+QIx3AuRHRLmkIsFTSzyIid2Td3wMzImKXpPcAXwLeJGkC8BlgBhBknl5fHBHb+hmLWb+0NI1m05YdbNq6g6NeMK7c4ZiVTZozjnslTe3PQSIj+zVtSPKKbnXujohd2WMBRyfLrwLujIhnk2RxJ5mzHrOSyvZzbNzsDnKrbWnOOGYCl0j6E5kzCJHJCQXdjiupnsyQ7C8EromI3/VS/VLgZ8nyUcBTOevWJ2Xd938ZcBlAS0sLra2tvcbT3t7eZ51qVattP9x2d+zeDsC9969iGJsHKKri8++7tpSi3WkSx2F9y4+I/cB0SeOA2ySdEhEPdq8n6a1kLkudky3Kt7s8+78OuA5gxowZMWvWrF7jaW1tpa861apW23647d6y6wGWPrCRUWOaK+rn5993bSlFuwtOHAM1LlVEbJfUSiYRdUkckuYAnwTOiYjsnVvrgVk51Y4mM/+5WUl52BGzjDR9HP0maWJypoGk4cAc4OFudU4HFgIXRsSmnFU/B+ZKGi9pPDA3KTMrqc4+Dj89bjWuVDejHwHckPRz1AE3R8Ttkq4CliUPFn4ZGAX8UBLAkxFxYUQ8K+mfgfuTfV0VEc+WKG6zTi2dicOd41bbSpI4ImIVcHqe8k/nLM/pZfvvAt8tTnRmhblvReZqbfvODl5/2ULe/dazmHt25kbDJfesZeGipWza2sakpjHMnzeTuWdPLXq5WTn48VezAiy5Zy1fWrik8/2mrTtY8O0l7Eumkv3qdf9Hx559QOaMZMG3l7Bi7Xp+/su1xSm/NhOLk4eVgxOHWQEWLlpKR8e+LmUde/bxL9+8I2/9jj37WHznoTMrD1h5xz4WLlrqxGFlUZLOcbNKt2nr4OvXGIwxWW1w4jArwKSmMXnLW5rHdA653l1dXb5HkAauvKeYzIrNicOsAPPnzaSxseuV3cbGBubPm9njuoteOa1o5Q31dcyfN/Nwm2XWL+7jMCtAti+htzub8q079cVHDWh59lbg5gmj3L9hZePEYVaguWdP7fHDuqd1A13esWcfF/39t/nz5jYe+9MmTjh+Uj9aYnZ4fKnKrII0Dm1g7lknAfCTXxwy1JtZSThxmFWY156XmRZnyT1r2bN3Xx+1zQaeE4dZhXnRlBZOOH4Sbe3Ps/T+x8sdjtUgJw6zCvSac08B4Ce/WF3mSKwWOXGYVaBXnnUSQxrquW/FEx500UrOicOsAo0dPZyzXvpCIuCO1rXlDsdqjBOHWYXKvVx14MAhk2KaFY0Th1mFmjHtOCY1jWbDxudY+dD6codjNcQPAJpVqPr6Oi6YfTI33HIv/3j1rXTs2Zd3Do+NW9poufHRoswF4nlFapMTh1kFGz1yGADPd3Sdq2P1w0/z09Y1nUPBD3R51oJrlwzIvpw8KosTh1kF++FPHjikrKNjH7f9fGVRy7PzkGQnsjqcfXlekcrjxGFWwco1J0f3hHE4PK9I5XHnuFkF62lOjmLPBdI0fiRN40cOyL48r0jlceIwq2DlmAuksbGBy992Dpe/7ZwB2ZfnFak8vlRlVsF6myckdw6PluaBnyMkK+2+vvW9X7Jl207qJP5p/lz3b1QgRVTfg0MzZsyIZcuW9VqntbWVWbNmlSagQaZW2+52Dw4Rweve+S22t+3mxn+/lGOOHF+U4wy2dpfK4bRb0vKImNFXPV+qMrOSksT0qUcDsHKtH1ysRE4cZlZyp009BoAVDz1V5kisP5w4zKzkfMZR2Zw4zKzkphzbzKgRjTyzqY0/b/ZzHJXGicPMSq6+vo5pJx0FwCoP0FhxnDjMrCxOSy5XrfDlqorjxGFmZXGa+zkqlhOHmZXFice3MKyxgXVPP8u253aWOxxLwYnDzMpiyJB6Tn7RkQCsXPt0maOxNJw4zKxspnf2c/h5jkrixGFmZeMO8srkxGFmZXPyCUfQ0FDH4+s209b+fLnDsQI5cZhZ2TQ2DuGkFx5BBKx+2P0clcKJw8zKysOPVB4nDjMrK/dzVJ6SJA5JwyTdJ2mlpDWSPpenztmSHpC0T9Ibuq3bL2lF8lpcipjNrDROPfFI6urEI3/cyK7de8odjhVx8htEAAAJxElEQVSgVGccHcC5EXEaMB04X9KZ3eo8Cbwd+EGe7XdHxPTkdWFxQzWzUho5opETjp/E/v0HWPPoM+UOxwpQksQRGe3J2yHJK7rVeSIiVgEHShGTmQ0e00/K9nP4eY5KULKpYyXVA8uBFwLXRMRHe6h3PXB7RNySU7YPWAHsA74YET/Os91lwGUALS0tZ9x00029xtPe3s6oUaP615gKV6ttd7sHr5/c8yS/XbkJgLGjh/LKlx/F9BObWPHIVu787dM8t2NPl3Kgx3UDVV6KY5Ti2GnMnj27oKljSz7nuKRxwG3A+yPiwTzrr+fQxHFkRGyQNAX4BXBeRDze0zE853jvarXtbvfgtOSetSz49hI69uzrLBs6pJ5XzPgLfr3scfbs3d+l/O1veDkA19/y20PW9bRN2vJSHOOcM1/EL3/3GHty2t04tIH3XTILgG/e0NrlZ9I4tIHzXnEid/36kcLKGxv46LvnMvfsqfl/8HkUOud4yRMHgKTPADsj4it51l1Pt8SRZj04cfSlVtvudg9Ofz3/OjZu8WROxdDSPIZbF15WcP1CE0ep7qqamJxpIGk4MAd4uMBtx0tqTJabgVcAa4sVq5mV1qatThrFUqyfbanuqjoCuFvSKuB+4M6IuF3SVZIuBJD0EknrgTcCCyWtSbY9CVgmaSVwN5k+DicOsyoxqWlM3vK6OuUtb2keQ0tzum3SlpfiGKU4dk8/28NVqruqVkXE6RExLSJOiYirkvJPR8TiZPn+iDg6IkZGRFNEnJyU/yYiTo2I05J//6MUMZtZacyfN5PGxoYuZY2NDVz0yml5y+fPm5l6m7TlpThGKY49f95MiqGh7ypmZsWT7bxduGgpm7a2MalpDPPnzWTu2VM59cVH5S3P6m2bjVvaaGnue1+Hc4xilR/Osbu3uxjK0jlebO4c712ttt3tri1ud3qDqnPczMyqhxOHmZml4sRhZmapOHGYmVkqThxmZpZKVd5VJWkzsK6Pas3AlhKEMxjVatvd7tridqd3XERM7KtSVSaOQkhaVshtZ9WoVtvudtcWt7t4fKnKzMxSceIwM7NUajlxXFfuAMqoVtvudtcWt7tIaraPw8zM+qeWzzjMzKwfnDjMzCyVmkwcks6X9IikP0j6WLnjKRZJ35W0SdKDOWUTJN0p6bHk3/HljLEYJB0j6W5JD0laI+mKpLyq2y5pmKT7JK1M2v25pPx4Sb9L2v3fkoaWO9ZikFQv6feSbk/e10q7n5C0WtIKScuSsqL+rddc4pBUD1wDXABMBd4sqTiD1pff9cD53co+BtwVEScAdyXvq80+4MMRcRJwJnB58juu9rZ3AOdGxGnAdOB8SWcCC4CvJ+3eBlxaxhiL6QrgoZz3tdJugNkRMT3n+Y2i/q3XXOIAXgr8ISL+GBF7gJuAi8ocU1FExD3As92KLwJuSJZvAC4uaVAlEBHPRMQDyfIOMh8mR1HlbY+M9uTtkOQVwLnALUl51bUbQNLRwGuA7yTvRQ20uxdF/VuvxcRxFPBUzvv1SVmtaImIZyDzAQtMKnM8RSVpMnA68DtqoO3J5ZoVwCbgTuBxYHtE7EuqVOvf+zeAfwIOJO+bqI12Q+bLwRJJyyVdlpQV9W+9FqeOzTeru+9JrkKSRgG3Ah+MiLbMl9DqFhH7gemSxgG3ASflq1baqIpL0muBTRGxXNKsbHGeqlXV7hyviIgNkiYBd0p6uNgHrMUzjvXAMTnvjwY2lCmWctgo6QiA5N9NZY6nKCQNIZM0FkXEj5Limmg7QERsB1rJ9PGMk5T9kliNf++vAC6U9ASZS8/nkjkDqfZ2AxARG5J/N5H5svBSivy3XouJ437ghOSOi6HA3wKLyxxTKS0GLkmWLwH+p4yxFEVyffs/gIci4ms5q6q67ZImJmcaSBoOzCHTv3M38IakWtW1OyI+HhFHR8RkMv+ffxER86jydgNIGilpdHYZmAs8SJH/1mvyyXFJrybzjaQe+G5EXF3mkIpC0o3ALDLDLG8EPgP8GLgZOBZ4EnhjRHTvQK9okmYCvwJWc/Ca9yfI9HNUbdslTSPTEVpP5kvhzRFxlaQpZL6JTwB+D7w1IjrKF2nxJJeqPhIRr62FdidtvC152wD8ICKultREEf/WazJxmJlZ/9XipSozMzsMThxmZpaKE4eZmaXixGFmZqk4cZiZWSpOHGZmlooTh5mZpeLEYVVBUkj6as77j0j67ADsd3LufCbFJOkDyRwiiw5zP+35ls0GihOHVYsO4PWSmssdSC5lFPr/7L3Aq5PhMswGLScOqxb7gOuAf8gt7H7GkD0TScoflvQdSQ9KWiRpjqRfJ7OmvTRnNw2SbpC0StItkkYk+3prMuPeCkkLk0nCssd8SNK3gAfoOqgmkj6UHPNBSR9Myq4FpgCLJXVpQ7L+bcnxV0r6r6Tsx8lQ2mtyhtPOKxnT6CfJ9g9KelOeOrdJ+rykX0n6s6Q5ve3TapcTh1WTa4B5ksYWWP+FwL8C04AXA28BZgIfITO2VdaJwHURMQ1oA94r6STgTWSGtJ4O7AfmddvmexFxekSsyxZKOgN4B/AyMiPXvkvS6RHxbjKjt86OiK/nBinpZOCTHJzd74pk1Tsj4gxgBvCBZHyinpwPbIiI0yLiFOCOPHVOITOHxVlkzn585mN5OXFY1YiINuB7wAcK3ORPEbE6Ig4Aa8hMtRlkBkecnFPvqYj4dbL8fTLJ5TzgDOD+ZOKk88icMWSti4h78xxzJnBbROxMZuv7EXBWH3GeC9wSEVuSdmYHq/uApJXAvWTOak7oZR+rgTmSFkg6KyKey12ZnEWNBbJJqwHY3kdcVqNqcSInq27fIHN56D+T9/vo+gVpWM5y7kipB3LeH6Dr/43uI4EGmYmCboiIj/cQx84eyvszm5S6x5CMAjsHeHlE7JLUSte2dRERjyZnO68GviBpSURclVPlZGB5MhEUZM7CSnJTgFUen3FYVUm+jd8MXJoUbQQmSWqS1Ai8th+7PVbSy5PlNwNLgbuANySzriFpgqTjCtjXPcDFkkYk8yf8FZkh4HtzF/A32UtRkiaQOTvYliSNF5O57NUjSUcCuyLi+8BXgL/sVuUUYEXO+2nAqgLaYzXIZxxWjb4KvA8gIvZKuorMXBx/AvozreZDwCWSFgKPAd9OPrCvJDPXcx2wF7gcWNfLfoiIByRdD9yXFH0nIn7fxzZrJF0N/FLSfjJzS8wH3i1pFfAImctVvTkV+LKkA0ms78mz/nc570/BZxzWA8/HYWZmqfhSlZmZpeLEYWZmqThxmJlZKk4cZmaWihOHmZml4sRhZmapOHGYmVkq/x/sbdledp5k+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "plot_convergence(res_gp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the experiment on the original toy data and try to automatically optimize the parameter `C` and `gamma` of a SVR classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
